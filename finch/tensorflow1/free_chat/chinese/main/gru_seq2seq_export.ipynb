{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gru_seq2seq_export.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tJIH75zLJTC3","colab_type":"code","outputId":"512d673c-0218-46f6-b316-079bdc7b78ff","executionInfo":{"status":"ok","timestamp":1569460582691,"user_tz":-480,"elapsed":2195,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\"\n","We use following lines because we are running on Google Colab\n","If you are running notebook on a local computer, you don't need this cell\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M5Jap8hmJYhu","colab_type":"code","outputId":"ade57297-482d-4189-a6b5-02ffaafad0c0","executionInfo":{"status":"ok","timestamp":1569460583529,"user_tz":-480,"elapsed":2976,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import tensorflow as tf\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow Version 1.14.0\n","GPU Enabled: False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZE3kRpHYJsw0","colab_type":"code","colab":{}},"source":["def rnn_cell():\n","    def cell_fn():\n","        cell = tf.nn.rnn_cell.GRUCell(params['rnn_units'],\n","                                      kernel_initializer=tf.orthogonal_initializer())\n","        return cell\n","    if params['dec_layers'] > 1:\n","      cells = []\n","      for i in range(params['dec_layers']):\n","        if i == params['dec_layers'] - 1:\n","          cells.append(cell_fn())\n","        else:\n","          cells.append(tf.nn.rnn_cell.ResidualWrapper(cell_fn(), residual_fn=lambda i,o: tf.concat((i,o), -1)))\n","      return tf.nn.rnn_cell.MultiRNNCell(cells)\n","    else:\n","      return cell_fn()\n","\n","  \n","def dec_cell(enc_out, enc_seq_len):\n","    attn = tf.contrib.seq2seq.BahdanauAttention(\n","        num_units = params['rnn_units'],\n","        memory = enc_out,\n","        memory_sequence_length = enc_seq_len,\n","        normalize=False)\n","    \n","    return tf.contrib.seq2seq.AttentionWrapper(\n","        cell = rnn_cell(),\n","        attention_mechanism = attn,\n","        attention_layer_size = params['rnn_units'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TM5euAk3JyBI","colab_type":"code","colab":{}},"source":["class TiedDense(tf.layers.Layer):\n","  def __init__(self, tied_embed, out_dim):\n","    super().__init__()\n","    self.tied_embed = tied_embed\n","    self.out_dim = out_dim\n","  \n","  def build(self, input_shape):\n","    self.bias = self.add_weight(name='bias',\n","                                shape=[self.out_dim],\n","                                trainable=True)\n","    if params['rnn_units'] != params['embed_dim']:\n","      self.proj_W = self.add_weight(name='proj_W',\n","                                    shape=[params['rnn_units'], params['embed_dim']],\n","                                    trainable=True)\n","      self.proj_b = self.add_weight(name='proj_b',\n","                                    shape=[params['embed_dim']],\n","                                    trainable=True)\n","    super().build(input_shape)\n","  \n","  def call(self, inputs):\n","    if params['rnn_units'] != params['embed_dim']:\n","      inputs = tf.nn.elu(tf.nn.bias_add(tf.matmul(inputs, self.proj_W), self.proj_b))\n","    x = tf.matmul(inputs, self.tied_embed, transpose_b=True)\n","    x = tf.nn.bias_add(x, self.bias)\n","    return x\n","  \n","  def compute_output_shape(self, input_shape):\n","    return input_shape[:-1].concatenate(self.out_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3d8hOgMJ1IR","colab_type":"code","colab":{}},"source":["def forward(features, labels, mode):\n","    if isinstance(features, dict):\n","      words = features['words']\n","    else:\n","      words = features\n","    \n","    words_len = tf.count_nonzero(words, 1, dtype=tf.int32)\n","    \n","    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","    batch_sz = tf.shape(words)[0]\n","    \n","    \n","    with tf.variable_scope('Embedding'):\n","        embedding = tf.get_variable('embedding', [len(params['char2idx'])+1, params['embed_dim']], tf.float32)\n","        x = tf.nn.embedding_lookup(embedding, words)\n","        x = tf.layers.dropout(x, params['dropout_rate'], training=is_training)\n","    \n","    \n","    with tf.variable_scope('Encoder'):\n","        cell_fw = tf.nn.rnn_cell.GRUCell(params['rnn_units'],\n","                                         kernel_initializer=tf.orthogonal_initializer())\n","        cell_bw = tf.nn.rnn_cell.GRUCell(params['rnn_units'],\n","                                         kernel_initializer=tf.orthogonal_initializer())\n","        (o_fw, o_bw), (s_fw, s_bw) = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x, words_len, dtype=tf.float32)\n","        enc_out = tf.concat((o_fw, o_bw), -1)\n","        enc_state = tf.layers.dense(tf.concat((s_fw, s_bw), -1), params['rnn_units'], tf.nn.elu, name='state_fc')\n","        if params['dec_layers'] > 1:\n","          enc_state = tuple(params['dec_layers'] * [enc_state])\n","    \n","    \n","    with tf.variable_scope('Decoder'):\n","        output_proj = TiedDense(embedding, len(params['char2idx'])+1)\n","        \n","        if is_training or (mode == tf.estimator.ModeKeys.EVAL):\n","            dec_inputs, dec_outputs = labels\n","            dec_seq_len = tf.count_nonzero(dec_inputs, 1, dtype=tf.int32)\n","            dec_inputs = tf.nn.embedding_lookup(embedding, dec_inputs)\n","            dec_inputs = tf.layers.dropout(dec_inputs, params['dropout_rate'], training=is_training)\n","            cell = dec_cell(enc_out, words_len)\n","            \n","            init_state = cell.zero_state(batch_sz, tf.float32).clone(\n","                cell_state=enc_state)\n","            \n","            helper = tf.contrib.seq2seq.TrainingHelper(\n","                inputs = dec_inputs,\n","                sequence_length = dec_seq_len,)\n","            decoder = tf.contrib.seq2seq.BasicDecoder(\n","                cell = cell,\n","                helper = helper,\n","                initial_state = init_state,\n","                output_layer = output_proj)\n","            decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","                decoder = decoder,\n","                maximum_iterations = tf.reduce_max(dec_seq_len))\n","            \n","            return decoder_output.rnn_output\n","        else:\n","            enc_out_t = tf.contrib.seq2seq.tile_batch(enc_out, params['beam_width'])\n","            enc_state_t = tf.contrib.seq2seq.tile_batch(enc_state, params['beam_width'])\n","            enc_seq_len_t = tf.contrib.seq2seq.tile_batch(words_len, params['beam_width'])\n","            \n","            cell = dec_cell(enc_out_t, enc_seq_len_t)\n","            \n","            init_state = cell.zero_state(batch_sz*params['beam_width'], tf.float32).clone(\n","                cell_state=enc_state_t)\n","            \n","            decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n","                cell = cell,\n","                embedding = embedding,\n","                start_tokens = tf.tile(tf.constant([1], tf.int32), [batch_sz]),\n","                end_token = 2,\n","                initial_state = init_state,\n","                beam_width = params['beam_width'],\n","                output_layer = output_proj,\n","                length_penalty_weight = params['length_penalty_weight'],\n","                coverage_penalty_weight = params['coverage_penalty_weight'],)\n","            decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","                decoder = decoder,\n","                maximum_iterations = 50,)\n","            \n","            return decoder_output.predicted_ids[:, :, :params['top_k']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ndq26dhcJ_X6","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","    logits_or_ids = forward(features, labels, mode)\n","    \n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode, predictions=logits_or_ids)\n","    \n","    dec_inputs, dec_outputs = labels\n","    loss_op = tf.contrib.seq2seq.sequence_loss(logits = logits_or_ids,\n","                                               targets = dec_outputs,\n","                                               weights = tf.to_float(tf.sign(dec_outputs)))  \n","      \n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","        global_step=tf.train.get_or_create_global_step()\n","        \n","        decay_lr = tf.train.exponential_decay(\n","            params['lr'], global_step, 1000, .96)\n","        \n","        train_op = tf.train.AdamOptimizer(decay_lr).apply_gradients(\n","            clip_grads(loss_op), global_step=global_step)\n","        \n","        hook = tf.train.LoggingTensorHook({'lr': decay_lr}, every_n_iter=100)\n","        \n","        return tf.estimator.EstimatorSpec(\n","            mode=mode, loss=loss_op, train_op=train_op, training_hooks=[hook],)\n","      \n","    if mode == tf.estimator.ModeKeys.EVAL:\n","      return tf.estimator.EstimatorSpec(mode=mode, loss=loss_op)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUtptCqjKCBc","colab_type":"code","colab":{}},"source":["params = {\n","    'model_dir': '../model/gru_seq2seq',\n","    'export_dir': '../model/gru_seq2seq_export',\n","    'log_path': '../log/gru_seq2seq.txt',\n","    'train_path': '../data/train.txt',\n","    'test_path': '../data/test.txt',\n","    'vocab_path': '../vocab/char.txt',\n","    'model_path': '../model/',\n","    'dropout_rate': 0.2,\n","    'embed_dim': 300,\n","    'rnn_units': 300,\n","    'dec_layers': 2,\n","    'beam_width': 10,\n","    'top_k': 5,\n","    'length_penalty_weight': .2,\n","    'coverage_penalty_weight': .2,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yA9cnR_cKFmD","colab_type":"code","colab":{}},"source":["def serving_input_receiver_fn():\n","    words = tf.placeholder(tf.int32, [None, None], 'words')\n","    \n","    features = {'words': words}\n","    receiver_tensors = features\n","    \n","    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NpHXFOdPMSmw","colab_type":"code","colab":{}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQCSv49ZMPPn","colab_type":"code","colab":{}},"source":["params['char2idx'] = get_vocab(params['vocab_path'])\n","params['idx2char'] = {idx: char for char, idx in params['char2idx'].items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JaOquMcTLB_D","colab_type":"code","outputId":"4b634c0e-666e-4147-a94f-96f05c97006e","executionInfo":{"status":"ok","timestamp":1569460588118,"user_tz":-480,"elapsed":6983,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["estimator = tf.estimator.Estimator(model_fn, params['model_dir'])\n","estimator.export_saved_model(params['export_dir'], serving_input_receiver_fn)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '../model/gru_seq2seq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbfd3bf6518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fbfd744c1e0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n","Instructions for updating:\n","reduction_indices is deprecated, use axis instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From <ipython-input-5-b8add7ecc149>:16: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From <ipython-input-5-b8add7ecc149>:21: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-5-b8add7ecc149>:24: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From <ipython-input-5-b8add7ecc149>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-3-882e176daf1d>:13: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:985: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:1266: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from ../model/gru_seq2seq/model.ckpt-101870\n","INFO:tensorflow:Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","INFO:tensorflow:SavedModel written to: ../model/gru_seq2seq_export/temp-b'1569460583'/saved_model.pb\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["b'../model/gru_seq2seq_export/1569460583'"]},"metadata":{"tags":[]},"execution_count":11}]}]}