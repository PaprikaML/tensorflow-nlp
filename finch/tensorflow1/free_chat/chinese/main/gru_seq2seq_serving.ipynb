{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gru_seq2seq_serving.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UgYivRzITeEN","colab_type":"code","outputId":"efa117bb-9e01-4f72-90fd-11595f21a24a","executionInfo":{"status":"ok","timestamp":1570518449850,"user_tz":-480,"elapsed":2267,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\"\n","We use following lines because we are running on Google Colab\n","If you are running notebook on a local computer, you don't need this cell\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aKyuaj7A5ugJ","colab_type":"code","colab":{}},"source":["!pip install -q requests\n","\n","import numpy as np\n","import requests\n","import json\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MN-uR5377XYb","colab_type":"code","outputId":"70d8f0c5-e48d-4183-c9de-2ae28509e0e8","executionInfo":{"status":"ok","timestamp":1570518468673,"user_tz":-480,"elapsed":20996,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n","curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n","!apt update\n","!apt-get install tensorflow-model-server"],"execution_count":3,"outputs":[{"output_type":"stream","text":["deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0   143k      0 --:--:-- --:--:-- --:--:--  143k\n","OK\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n","Hit:2 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Fetched 74.6 kB in 3s (29.8 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","145 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","tensorflow-model-server is already the newest version (1.14.0).\n","0 upgraded, 0 newly installed, 0 to remove and 145 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vAHOlAP_8nqx","colab_type":"code","colab":{}},"source":["os.environ[\"MODEL_DIR\"] = '/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/model/gru_seq2seq_export'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rf8szeGGToWO","colab_type":"code","outputId":"a1f1650a-1955-4a17-cda9-55286ba3d16b","executionInfo":{"status":"ok","timestamp":1570518468690,"user_tz":-480,"elapsed":20978,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%bash --bg \n","nohup tensorflow_model_server \\\n","  --rest_api_port=8508 \\\n","  --model_name=fashion_model \\\n","  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Starting job # 0 in a separate thread.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cmOgdTFv9Poh","colab_type":"code","outputId":"9b214c78-c5a5-4880-87e8-19d083ab9f0f","executionInfo":{"status":"ok","timestamp":1570518472451,"user_tz":-480,"elapsed":24723,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["!tail server.log"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2019-10-08 07:07:48.360162: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2019-10-08 07:07:48.400487: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n","2019-10-08 07:07:48.501425: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: /content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/model/gru_seq2seq_export/1569460583\n","2019-10-08 07:07:48.524402: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 179840 microseconds.\n","2019-10-08 07:07:48.525142: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:103] No warmup data file found at /content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/model/gru_seq2seq_export/1569460583/assets.extra/tf_serving_warmup_requests\n","2019-10-08 07:07:48.528559: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: fashion_model version: 1569460583}\n","2019-10-08 07:07:48.530607: I tensorflow_serving/model_servers/server.cc:324] Running gRPC ModelServer at 0.0.0.0:8500 ...\n","[warn] getaddrinfo: address family for nodename not supported\n","2019-10-08 07:07:48.531879: I tensorflow_serving/model_servers/server.cc:344] Exporting HTTP/REST API at:localhost:8508 ...\n","[evhttp_server.cc : 239] RAW: Entering the event loop ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvljYv95AE4F","colab_type":"code","colab":{}},"source":["def get_vocab(f_path):\n","  k2v = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      k2v[line] = i\n","  return k2v\n","\n","parse_fn = lambda text: [[CHAR2IDX.get(c, len(CHAR2IDX)) for c in list(text)]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnzUpVLW_L3j","colab_type":"code","outputId":"ec63f109-9a82-41f2-8d7c-e3a017793e40","executionInfo":{"status":"ok","timestamp":1570518472462,"user_tz":-480,"elapsed":24708,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["CHAR2IDX = get_vocab('../vocab/char.txt')\n","data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": parse_fn('你是谁')})\n","print(data)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{\"signature_name\": \"serving_default\", \"instances\": [[10, 13, 119]]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gaV2V9wNBLA_","colab_type":"code","outputId":"20f818fc-8159-4a04-9dda-51a9fac8df2d","executionInfo":{"status":"ok","timestamp":1570518473909,"user_tz":-480,"elapsed":26142,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["headers = {\"content-type\": \"application/json\"}\n","json_response = requests.post('http://localhost:8508/v1/models/fashion_model:predict', data=data, headers=headers)\n","print(json_response)\n","predictions = json.loads(json_response.text)['predictions']"],"execution_count":9,"outputs":[{"output_type":"stream","text":["<Response [200]>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRUYS8xyJR5a","colab_type":"code","outputId":"93868a6c-1d8d-45f1-91d1-1cc4e1ed0950","executionInfo":{"status":"ok","timestamp":1570518473911,"user_tz":-480,"elapsed":26128,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["predictions = np.asarray(predictions)\n","IDX2CHAR = {idx: char for char, idx in CHAR2IDX.items()}\n","for j in range(5):\n","  print('A{}:'.format(j+1), ' '.join([IDX2CHAR.get(idx, len(IDX2CHAR)) for idx in predictions[0, :, j]]).replace('<end>', ''))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["A1: 我 是 小 通                  \n","A2: 我 是 小 黄 鹰                 \n","A3: 不 是 她 们 俩 吗 ？               \n","A4: 我 是 小 通 ~                 \n","A5: 我 是 宇 宙 无 敌 可 爱 小 通            \n"],"name":"stdout"}]}]}