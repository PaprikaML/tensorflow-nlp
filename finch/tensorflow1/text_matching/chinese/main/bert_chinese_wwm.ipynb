{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_chinese_wwm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOVonplQDAO5WxQyjV6h0S7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_4hsiHfLy047","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/text_matching/chinese/main')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"61staQgJy7Ax","colab_type":"code","outputId":"e6e4384d-787b-4808-f496-3f3eb36000b4","executionInfo":{"status":"ok","timestamp":1587541211735,"user_tz":-480,"elapsed":11863,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["%tensorflow_version 1.x\n","!pip install bert4keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting bert4keras\n","  Downloading https://files.pythonhosted.org/packages/4c/74/2ae8881809ba94de837063eb569de4a9f78197324e7267bdf9019503e73e/bert4keras-0.7.3.tar.gz\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from bert4keras) (2.3.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.0.8)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.18.2)\n","Building wheels for collected packages: bert4keras\n","  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert4keras: filename=bert4keras-0.7.3-cp36-none-any.whl size=35440 sha256=bd229379a790e6f5c0fc05c773dda15b3f7b96d3bb8f268a859bef1283e3aa18\n","  Stored in directory: /root/.cache/pip/wheels/1c/85/90/765bba4e2b5ea63654914564156c98c0bb2744da53e14233e4\n","Successfully built bert4keras\n","Installing collected packages: bert4keras\n","Successfully installed bert4keras-0.7.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T3KPPoB1zZcz","colab_type":"code","outputId":"305ac2e4-f259-4a69-8b4f-22db5bf9e3ba","executionInfo":{"status":"ok","timestamp":1587541217548,"user_tz":-480,"elapsed":15748,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["import numpy as np\n","import csv\n","\n","from bert4keras.backend import keras, set_gelu, K\n","from bert4keras.tokenizers import Tokenizer\n","from bert4keras.models import build_transformer_model\n","from bert4keras.optimizers import Adam\n","from bert4keras.snippets import sequence_padding, DataGenerator\n","from bert4keras.snippets import open\n","from keras.layers import Dropout, Dense"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WNM3xIJZy-Ag","colab_type":"code","colab":{}},"source":["def load_data(filename):\n","    D = []\n","    with open(filename, encoding='utf-8') as f:\n","      for i, line in enumerate(csv.reader(f, delimiter=',')):\n","        if i == 0:\n","          continue\n","        text1, text2, label = line\n","        D.append((text1, text2, int(label)))\n","    return D\n","\n","\n","class data_generator(DataGenerator):\n","    def __iter__(self, random=False):\n","        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","        for is_end, (text1, text2, label) in self.sample(random):\n","            token_ids, segment_ids = tokenizer.encode(\n","                text1, text2, max_length=maxlen\n","            )\n","            batch_token_ids.append(token_ids)\n","            batch_segment_ids.append(segment_ids)\n","            batch_labels.append([label])\n","            if len(batch_token_ids) == self.batch_size or is_end:\n","                batch_token_ids = sequence_padding(batch_token_ids)\n","                batch_segment_ids = sequence_padding(batch_segment_ids)\n","                batch_labels = sequence_padding(batch_labels)\n","                yield [batch_token_ids, batch_segment_ids], batch_labels\n","                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","\n","\n","def evaluate(data):\n","    total, right = 0., 0.\n","    for x_true, y_true in data:\n","        y_pred = model.predict(x_true).argmax(axis=1)\n","        y_true = y_true[:, 0]\n","        total += len(y_true)\n","        right += (y_true == y_pred).sum()\n","    return right / total\n","\n","\n","class Evaluator(keras.callbacks.Callback):\n","    def __init__(self):\n","        self.best_val_acc = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        val_acc = evaluate(test_generator)\n","        if val_acc > self.best_val_acc:\n","            self.best_val_acc = val_acc\n","            # you can save your model here\n","        print(\n","            'val_acc: {:.4f}, best_val_acc: {:.4f}'.format\n","            (val_acc, self.best_val_acc)\n","        )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"isZ4JExmzEnp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"93e65750-50fa-4f65-f719-df52d93a60a1"},"source":["set_gelu('tanh')\n","maxlen = 64\n","batch_size = 32\n","config_path = '../model/chinese_wwm_L-12_H-768_A-12/bert_config.json'\n","checkpoint_path = '../model/chinese_wwm_L-12_H-768_A-12/bert_model.ckpt'\n","dict_path = '../model/chinese_wwm_L-12_H-768_A-12/vocab.txt'\n","\n","train_data = load_data('../data/train.csv')\n","test_data = load_data('../data/test.csv')\n","\n","tokenizer = Tokenizer(dict_path, do_lower_case=True)\n","\n","train_generator = data_generator(train_data, batch_size)\n","test_generator = data_generator(test_data, batch_size)\n","\n","bert = build_transformer_model(\n","    config_path=config_path,\n","    checkpoint_path=checkpoint_path,\n","    with_pool=True,\n","    return_keras_model=False,\n",")\n","\n","output = Dropout(rate=.1)(bert.model.output)\n","output = Dense(\n","    units=2, activation='softmax', kernel_initializer=bert.initializer\n",")(output)\n","\n","model = keras.models.Model(bert.model.input, output)\n","model.summary()\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=Adam(2e-5),\n","    metrics=['accuracy'],\n",")\n","\n","evaluator = Evaluator()\n","model.fit_generator(\n","    train_generator.forfit(),\n","    steps_per_epoch=len(train_generator),\n","    epochs=10,\n","    callbacks=[evaluator]\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n","                                                                 Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","                                                                 Transformer-0-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","                                                                 Transformer-1-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","                                                                 Transformer-2-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","                                                                 Transformer-3-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","                                                                 Transformer-4-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","                                                                 Transformer-5-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","                                                                 Transformer-6-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","                                                                 Transformer-7-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","                                                                 Transformer-8-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","                                                                 Transformer-9-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","                                                                 Transformer-10-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","                                                                 Transformer-11-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Pooler (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Pooler-Dense (Dense)            (None, 768)          590592      Pooler[0][0]                     \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 768)          0           Pooler-Dense[0][0]               \n","__________________________________________________________________________________________________\n","dense_73 (Dense)                (None, 2)            1538        dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 102,269,186\n","Trainable params: 102,269,186\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/10\n","3125/3125 [==============================] - 2416s 773ms/step - loss: 0.3431 - accuracy: 0.8508\n","val_acc: 0.8422, best_val_acc: 0.8422\n","Epoch 2/10\n","3125/3125 [==============================] - 2416s 773ms/step - loss: 0.1735 - accuracy: 0.9338\n","val_acc: 0.8425, best_val_acc: 0.8425\n","Epoch 3/10\n","3125/3125 [==============================] - 2404s 769ms/step - loss: 0.1021 - accuracy: 0.9628\n","val_acc: 0.8500, best_val_acc: 0.8500\n","Epoch 4/10\n","3125/3125 [==============================] - 2405s 770ms/step - loss: 0.0684 - accuracy: 0.9754\n","val_acc: 0.8374, best_val_acc: 0.8500\n","Epoch 5/10\n","3125/3125 [==============================] - 2411s 772ms/step - loss: 0.0531 - accuracy: 0.9807\n","val_acc: 0.8405, best_val_acc: 0.8500\n","Epoch 6/10\n","3125/3125 [==============================] - 2407s 770ms/step - loss: 0.0436 - accuracy: 0.9847\n","val_acc: 0.8448, best_val_acc: 0.8500\n","Epoch 7/10\n"," 771/3125 [======>.......................] - ETA: 30:15 - loss: 0.0297 - accuracy: 0.9896"],"name":"stdout"}]}]}