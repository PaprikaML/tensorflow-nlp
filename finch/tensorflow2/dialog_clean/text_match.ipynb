{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_match.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2AmzAFs-s22t","colab_type":"code","outputId":"ef465ee3-6bba-4b1c-a0ff-c54100289a73","executionInfo":{"status":"ok","timestamp":1570753039986,"user_tz":-480,"elapsed":49058,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["\"\"\"\n","We use following lines because we are running on Google Colab\n","If you are running notebook on a local computer, you don't need this cell\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow2/dialog_clean/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HBaiJLp48yGR","colab_type":"code","outputId":"b5dcaf47-e6cd-44b6-8d45-2b8681dbbb2c","executionInfo":{"status":"ok","timestamp":1570753086172,"user_tz":-480,"elapsed":95210,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["!pip install tensorflow-gpu==2.0.0-rc1"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n","\u001b[K     |████████████████████████████████| 380.5MB 79kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.7)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.16.5)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n","Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0-rc1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n","\u001b[K     |████████████████████████████████| 4.3MB 32.2MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n","Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0-rc1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n","\u001b[K     |████████████████████████████████| 501kB 41.1MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.33.6)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (41.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.16.0)\n","Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n","Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lTtoUQFd-syK","colab_type":"code","outputId":"7298a373-179f-46d7-a1eb-5e281dce3add","executionInfo":{"status":"ok","timestamp":1570753089377,"user_tz":-480,"elapsed":98390,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import tensorflow as tf\n","\n","import numpy as np\n","import pprint\n","import logging\n","import time\n","import os\n","import random\n","import math\n","\n","from pathlib import Path\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow Version 2.0.0-rc1\n","GPU Enabled: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"65Z9kT3ks_7K","colab_type":"code","colab":{}},"source":["# stream data from text files\n","def data_generator(params, is_training):\n","  last = '我好想你'\n","  with open(params['train_path']) as f:\n","    print('Reading', params['train_path'])\n","    for line in f:\n","      line = line.rstrip()\n","      sp = line.split('|')\n","      if len(sp) == 2:\n","        source, target = sp\n","      else:\n","        continue\n","      _source = [params['char2idx'].get(c, len(params['char2idx'])) for c in source]\n","      _target = [params['char2idx'].get(c, len(params['char2idx'])) for c in target]\n","      _last = [params['char2idx'].get(c, len(params['char2idx'])) for c in last]\n","      if len(_source) > params['max_len']:\n","        _source = _source[:params['max_len']]\n","      if len(_target) > params['max_len']:\n","        _target = _target[:params['max_len']]\n","      if len(_last) > params['max_len']:\n","        _last = _last[:params['max_len']]\n","      \n","      if is_training:\n","        yield ((_source, _target), 1)\n","        yield ((_last, _target), 0)\n","        last = source\n","      else:\n","        yield ((_source, _target), 1)\n","\n","      \n","def dataset(params, is_training):\n","  _shapes = (([None], [None]), ())\n","  _types = ((tf.int32, tf.int32), tf.int32)\n","  _pads = ((0, 0), -1)\n","  \n","  ds = tf.data.Dataset.from_generator(\n","    lambda: data_generator(params=params, is_training=is_training),\n","    output_shapes = _shapes,\n","    output_types = _types,)\n","  if is_training:\n","    ds = ds.shuffle(200000)\n","  ds = ds.padded_batch(params['batch_size'], _shapes, _pads)\n","  \n","  return ds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NodvccOy3Xx","colab_type":"code","colab":{}},"source":["class RE2(tf.keras.Model):\n","  def __init__(self, params: dict):\n","    super().__init__()\n","    \n","    self.embedding = tf.keras.layers.Embedding(params['vocab_size'], params['hidden_size'])\n","    self.embed_dropout = tf.keras.layers.Dropout(params['dropout_rate'])\n","    \n","    self.birnn = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n","        params['hidden_size'], return_sequences=True), name='birnn_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.enc_dropout = tf.keras.layers.Dropout(params['dropout_rate'])\n","    \n","    self.align_t = self.add_weight(name='temperature',\n","                                   shape=(),\n","                                   trainable=True,\n","                                   initializer=tf.initializers.constant(math.sqrt(1/params['hidden_size'])))\n","    self.align_dropout = tf.keras.layers.Dropout(params['dropout_rate'])\n","    self.align_fc1 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='align_fc1_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.align_fc2 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='align_fc2_%d'%(i+1)) for i in range(params['num_blocks'])]\n","      \n","    self.fusion_fc1 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='fusion_fc1_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.fusion_fc2 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='fusion_fc2_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.fusion_fc3 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='fusion_fc3_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.fusion_fc4 = [tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='fusion_fc4_%d'%(i+1)) for i in range(params['num_blocks'])]\n","    self.fusion_dropout = tf.keras.layers.Dropout(params['dropout_rate'])\n","    \n","    self.out_drop1 = tf.keras.layers.Dropout(params['dropout_rate'])\n","    self.out_fc = tf.keras.layers.Dense(params['hidden_size'], params['activation'], name='out_fc')\n","    self.out_drop2 = tf.keras.layers.Dropout(params['dropout_rate'])\n","    self.out_linear = tf.keras.layers.Dense(1, name='out_linear')\n","    \n","  \n","  \n","  def call(self, inputs, training=False):\n","    x1, x2 = inputs\n","    \n","    batch_sz = tf.shape(x1)[0]\n","    \n","    mask1 = tf.sign(x1)\n","    mask2 = tf.sign(x2)\n","    \n","    x1 = self.embedding(x1)\n","    x2 = self.embedding(x2)\n","    x1 = self.embed_dropout(x1, training=training)\n","    x2 = self.embed_dropout(x2, training=training)\n","    \n","    res_x1, res_x2 = x1, x2\n","    \n","    for i in range(params['num_blocks']):\n","      \n","      if i > 0:\n","        x1 = self.connection(x1, res_x1, i)\n","        x2 = self.connection(x2, res_x2, i)\n","        res_x1, res_x2 = x1, x2\n","    \n","      x1_enc = self.encoding(x1, mask1, i, training=training)\n","      x2_enc = self.encoding(x2, mask2, i, training=training)\n","    \n","      x1 = tf.concat((x1, x1_enc), -1)\n","      x2 = tf.concat((x2, x2_enc), -1)\n","      \n","      align_1, align_2 = self.alignment(x1, x2, mask1, mask2, i, training=training)\n","      \n","      x1 = self.fusion(x1, align_1, i, training=training)\n","      x2 = self.fusion(x2, align_2, i, training=training)\n","    \n","    x1 = self.pooling(x1, mask1)\n","    x2 = self.pooling(x2, mask2)\n","    \n","    x = self.prediction(x1, x2, training=training)\n","    \n","    return x\n","  \n","  \n","  def connection(self, x, res, i):\n","    if i == 1:\n","      x = tf.concat((res, x), -1)\n","    elif i > 1:\n","      hidden_size = x.shape[-1]\n","      x = (res[:, :, -hidden_size:] + x) * tf.math.sqrt(0.5)\n","      x = tf.concat((res[:, :, :-hidden_size], x), -1)\n","    return x\n","    \n","    \n","  def encoding(self, x, mask, i, training):\n","    mask = tf.cast(tf.expand_dims(mask, -1), tf.float32)\n","    x *= mask\n","    x = self.birnn[i](x)\n","    x = self.enc_dropout(x)\n","    return x\n","  \n","  \n","  def alignment(self, x1, x2, mask1, mask2, i, training):\n","    mask1 = tf.cast(tf.expand_dims(mask1, -1), tf.float32)\n","    mask2 = tf.cast(tf.expand_dims(mask2, -1), tf.float32)\n","    \n","    x1_ = self.align_fc1[i](self.align_dropout(x1, training=training))\n","    x2_ = self.align_fc2[i](self.align_dropout(x2, training=training))\n","    align = tf.matmul(x1_, x2_, transpose_b=True) * self.align_t\n","    mask = tf.matmul(mask1, mask2, transpose_b=True)\n","    align = mask * align + (1 - mask) * tf.float32.min\n","    align_1 = tf.nn.softmax(align, 1)\n","    align_2 = tf.nn.softmax(align, 2)\n","    \n","    x2 = tf.matmul(align_1, x1, transpose_a=True)\n","    x1 = tf.matmul(align_2, x2)\n","    return x1, x2\n","  \n","  \n","  def fusion(self, x, align, i, training):\n","    x = tf.concat([self.fusion_fc1[i](tf.concat((x, align), -1)),\n","                   self.fusion_fc2[i](tf.concat((x, x - align), -1)),\n","                   self.fusion_fc3[i](tf.concat((x, x * align), -1))], -1)\n","    x = self.fusion_dropout(x, training=training)\n","    x = self.fusion_fc4[i](x)\n","    return x\n","  \n","  \n","  def pooling(self, x, mask):\n","    mask = tf.cast(tf.expand_dims(mask, -1), tf.float32)\n","    return tf.reduce_max(x * mask, 1)\n","  \n","  \n","  def prediction(self, x1, x2, training):\n","    x = tf.concat((x1, x2, x1 * x2, x1 - x2), -1)\n","    x = self.out_drop1(x, training=training)\n","    x = self.out_fc(x)\n","    x = self.out_drop2(x, training=training)\n","    x = self.out_linear(x)\n","    x = tf.squeeze(x, -1)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlBQjWpbEQDD","colab_type":"code","colab":{}},"source":["def get_vocab(f_path):\n","  k2v = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      k2v[line] = i\n","  return k2v"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"958Gx5ery-uo","colab_type":"code","colab":{}},"source":["def is_descending(history: list):\n","  history = history[-(params['num_patience']+1):]\n","  for i in range(1, len(history)):\n","    if history[i-1] <= history[i]:\n","      return False\n","  return True "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rYU8tGqEfuB","colab_type":"code","colab":{}},"source":["params = {\n","  'train_path': './train_cleaned.txt',\n","  'vocab_path': './char.txt',\n","  'batch_size': 512,\n","  'max_len': 50,\n","  'buffer_size': 400000,\n","  'num_blocks': 2,\n","  'dropout_rate': 0.2,\n","  'hidden_size': 150,\n","  'activation': tf.nn.relu,\n","  'lr': 4e-4,\n","  'clip_norm': 5.,\n","  'eval_steps': 1000,\n","  'num_patience': 5,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Utha5BOEV_2","colab_type":"code","colab":{}},"source":["params['char2idx'] = get_vocab('char.txt')\n","params['vocab_size'] = len(params['char2idx']) + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJJIKuTx6Mk9","colab_type":"code","outputId":"eab21a95-e862-45e6-bfc3-f29ac2ba7e67","executionInfo":{"status":"error","timestamp":1570754398417,"user_tz":-480,"elapsed":1407372,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = RE2(params)\n","model.build([[None, None], [None, None]])\n","pprint.pprint([(v.name, v.shape) for v in model.trainable_variables])\n","#model.load_weights('model')\n","\n","decay_lr = tf.optimizers.schedules.ExponentialDecay(params['lr'], 1000, 0.99)\n","optim = tf.optimizers.Adam(params['lr'])\n","global_step = 0\n","\n","history_acc = []\n","best_acc = .0\n","\n","t0 = time.time()\n","logger = logging.getLogger('tensorflow')\n","logger.setLevel(logging.INFO)\n","\n","while True:\n","  # TRAINING\n","  for ((text1, text2), label) in dataset(params=params, is_training=True):\n","    with tf.GradientTape() as tape:\n","      logits = model((text1, text2), training=True)\n","      loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(label, tf.float32), logits=logits)\n","      loss = tf.reduce_mean(loss)\n","      \n","    optim.lr.assign(decay_lr(global_step))\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    grads, _ = tf.clip_by_global_norm(grads, params['clip_norm'])\n","    optim.apply_gradients(zip(grads, model.trainable_variables))\n","    \n","    if global_step % 50 == 0:\n","      logger.info(\"Step {} | Loss: {:.4f} | Spent: {:.1f} secs | LR: {:.6f}\".format(\n","          global_step, loss.numpy().item(), time.time()-t0, optim.lr.numpy().item()))\n","      t0 = time.time()\n","    global_step += 1\n","  \n","    if global_step % params['eval_steps'] == 0:\n","      # EVALUATION\n","      m = tf.keras.metrics.Accuracy()\n","      \n","      scores = []\n","      for ((text1, text2), label) in dataset(params=params, is_training=False):\n","        logits = model((text1, text2), training=False)\n","        _scores = tf.sigmoid(logits)\n","        scores.append(_scores.numpy())\n","        y_pred = tf.cast(tf.math.round(_scores), tf.int32)\n","        m.update_state(y_true=label, y_pred=y_pred)\n","      \n","      scores = np.concatenate(scores)\n","      \n","      pairs = []\n","      with open(params['train_path']) as f:\n","        print('Reading', params['train_path'])\n","        for line in f:\n","          line = line.rstrip()\n","          sp = line.split('|')\n","          if len(sp) == 2:\n","            source, target = sp\n","          else:\n","            continue\n","          pairs.append((source, target))\n","      pairs = pairs[:len(scores)]\n","      pair_scores = [(source, target, score) for (source, target), score in zip(pairs, scores)]\n","      pair_scores.sort(key=lambda x: x[2])\n","      with open('score.txt', 'w') as f:\n","        for pair_score in reversed(pair_scores):\n","          source, target, score = pair_score\n","          f.write(source+'|'+target+'|'+str(score)+'\\n')\n","\n","      acc = m.result().numpy()\n","      logger.info(\"Evaluation: Testing Accuracy: {:.3f}\".format(acc))\n","      history_acc.append(acc)\n","      \n","      if acc > best_acc:\n","        best_acc = acc\n","        model.save_weights('model')\n","      logger.info(\"Best Accuracy: {:.3f}\".format(best_acc))\n","\n","      if len(history_acc) > params['num_patience'] and is_descending(history_acc):\n","        logger.info(\"Testing Accuracy not improved over {} epochs, Early Stop\".format(params['num_patience']))\n","        break"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[('embedding/embeddings:0', TensorShape([5751, 150])),\n"," ('birnn_1/forward_lstm/kernel:0', TensorShape([150, 600])),\n"," ('birnn_1/forward_lstm/recurrent_kernel:0', TensorShape([150, 600])),\n"," ('birnn_1/forward_lstm/bias:0', TensorShape([600])),\n"," ('birnn_1/backward_lstm/kernel:0', TensorShape([150, 600])),\n"," ('birnn_1/backward_lstm/recurrent_kernel:0', TensorShape([150, 600])),\n"," ('birnn_1/backward_lstm/bias:0', TensorShape([600])),\n"," ('birnn_2/forward_lstm_1/kernel:0', TensorShape([300, 600])),\n"," ('birnn_2/forward_lstm_1/recurrent_kernel:0', TensorShape([150, 600])),\n"," ('birnn_2/forward_lstm_1/bias:0', TensorShape([600])),\n"," ('birnn_2/backward_lstm_1/kernel:0', TensorShape([300, 600])),\n"," ('birnn_2/backward_lstm_1/recurrent_kernel:0', TensorShape([150, 600])),\n"," ('birnn_2/backward_lstm_1/bias:0', TensorShape([600])),\n"," ('align_fc1_1/kernel:0', TensorShape([450, 150])),\n"," ('align_fc1_1/bias:0', TensorShape([150])),\n"," ('align_fc1_2/kernel:0', TensorShape([600, 150])),\n"," ('align_fc1_2/bias:0', TensorShape([150])),\n"," ('align_fc2_1/kernel:0', TensorShape([450, 150])),\n"," ('align_fc2_1/bias:0', TensorShape([150])),\n"," ('align_fc2_2/kernel:0', TensorShape([600, 150])),\n"," ('align_fc2_2/bias:0', TensorShape([150])),\n"," ('fusion_fc1_1/kernel:0', TensorShape([900, 150])),\n"," ('fusion_fc1_1/bias:0', TensorShape([150])),\n"," ('fusion_fc1_2/kernel:0', TensorShape([1200, 150])),\n"," ('fusion_fc1_2/bias:0', TensorShape([150])),\n"," ('fusion_fc2_1/kernel:0', TensorShape([900, 150])),\n"," ('fusion_fc2_1/bias:0', TensorShape([150])),\n"," ('fusion_fc2_2/kernel:0', TensorShape([1200, 150])),\n"," ('fusion_fc2_2/bias:0', TensorShape([150])),\n"," ('fusion_fc3_1/kernel:0', TensorShape([900, 150])),\n"," ('fusion_fc3_1/bias:0', TensorShape([150])),\n"," ('fusion_fc3_2/kernel:0', TensorShape([1200, 150])),\n"," ('fusion_fc3_2/bias:0', TensorShape([150])),\n"," ('fusion_fc4_1/kernel:0', TensorShape([450, 150])),\n"," ('fusion_fc4_1/bias:0', TensorShape([150])),\n"," ('fusion_fc4_2/kernel:0', TensorShape([450, 150])),\n"," ('fusion_fc4_2/bias:0', TensorShape([150])),\n"," ('out_fc/kernel:0', TensorShape([600, 150])),\n"," ('out_fc/bias:0', TensorShape([150])),\n"," ('out_linear/kernel:0', TensorShape([150, 1])),\n"," ('out_linear/bias:0', TensorShape([1])),\n"," ('temperature:0', TensorShape([]))]\n","Reading ./train_cleaned.txt\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","INFO:tensorflow:Step 0 | Loss: 0.6932 | Spent: 42.5 secs | LR: 0.000400\n","INFO:tensorflow:Step 50 | Loss: 0.6869 | Spent: 47.6 secs | LR: 0.000400\n","INFO:tensorflow:Step 100 | Loss: 0.5737 | Spent: 47.5 secs | LR: 0.000400\n","INFO:tensorflow:Step 150 | Loss: 0.5933 | Spent: 47.6 secs | LR: 0.000399\n","INFO:tensorflow:Step 200 | Loss: 0.5172 | Spent: 47.9 secs | LR: 0.000399\n","INFO:tensorflow:Step 250 | Loss: 0.4928 | Spent: 47.4 secs | LR: 0.000399\n","INFO:tensorflow:Step 300 | Loss: 0.4957 | Spent: 47.6 secs | LR: 0.000399\n","INFO:tensorflow:Step 350 | Loss: 0.4903 | Spent: 48.0 secs | LR: 0.000399\n","INFO:tensorflow:Step 400 | Loss: 0.4497 | Spent: 47.5 secs | LR: 0.000398\n","INFO:tensorflow:Step 450 | Loss: 0.4358 | Spent: 46.9 secs | LR: 0.000398\n","INFO:tensorflow:Step 500 | Loss: 0.4557 | Spent: 47.7 secs | LR: 0.000398\n","INFO:tensorflow:Step 550 | Loss: 0.4225 | Spent: 47.8 secs | LR: 0.000398\n","INFO:tensorflow:Step 600 | Loss: 0.3854 | Spent: 47.0 secs | LR: 0.000398\n","INFO:tensorflow:Step 650 | Loss: 0.3589 | Spent: 46.9 secs | LR: 0.000397\n","INFO:tensorflow:Step 700 | Loss: 0.3951 | Spent: 47.1 secs | LR: 0.000397\n","INFO:tensorflow:Step 750 | Loss: 0.3397 | Spent: 45.8 secs | LR: 0.000397\n","INFO:tensorflow:Step 800 | Loss: 0.3314 | Spent: 42.1 secs | LR: 0.000397\n","INFO:tensorflow:Step 850 | Loss: 0.3380 | Spent: 41.9 secs | LR: 0.000397\n","INFO:tensorflow:Step 900 | Loss: 0.3225 | Spent: 41.6 secs | LR: 0.000396\n","INFO:tensorflow:Step 950 | Loss: 0.2701 | Spent: 40.8 secs | LR: 0.000396\n","Reading ./train_cleaned.txt\n","Reading ./train_cleaned.txt\n","INFO:tensorflow:Evaluation: Testing Accuracy: 0.993\n","INFO:tensorflow:Best Accuracy: 0.993\n","INFO:tensorflow:Step 1000 | Loss: 0.3261 | Spent: 354.3 secs | LR: 0.000396\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d2428f689ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clip_norm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m           update_ops.extend(\n\u001b[1;32m    484\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 485\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    202\u001b[0m           \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;34m\"ResourceApplyAdam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mbeta1_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m         \"use_locking\", use_locking, \"use_nesterov\", use_nesterov)\n\u001b[0m\u001b[1;32m   1526\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}